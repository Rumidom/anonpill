{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d9df104c-61ac-4170-9ddc-212f705e6d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import requests\n",
    "from IPython.display import clear_output\n",
    "import glob\n",
    "import shutil\n",
    "\n",
    "def getLinks(filepath,datasetname):\n",
    "    links = []\n",
    "    with open(filepath) as file:\n",
    "        content = file.read()\n",
    "        links = content.splitlines()\n",
    "    downloadedpaths = glob.glob(datasetname+'/**/*.jpg', recursive=True)\n",
    "    downloadedFilenames = [filename.split('/')[-1] for filename in downloadedpaths]\n",
    "    output = []\n",
    "    for link in links:\n",
    "        if not getlinkparams(link)['dl'] in downloadedFilenames:\n",
    "            output.append(link)\n",
    "    return output\n",
    "\n",
    "def splitLinks(links,split,shuffle = False):\n",
    "    if shuffle: \n",
    "        random.shuffle(links)\n",
    "    train = links[:int(len(links)*split)]\n",
    "    validation = links[-int(len(links)*(1.0-split)):]\n",
    "    return train,validation\n",
    "\n",
    "def getlinkparams(link):\n",
    "    #print(link)\n",
    "    l = link.split('?')[1].split('&')\n",
    "    di = {}\n",
    "    for item in l:\n",
    "        item_l = item.split('=')\n",
    "        di[item_l[0]] = item_l[1]\n",
    "    return di\n",
    "\n",
    "def removeDuplicates(filepath):\n",
    "    links = []\n",
    "    with open(filepath) as file:\n",
    "        content = file.read()\n",
    "        links = content.splitlines()\n",
    "    print(\"Original:\",len(links))\n",
    "    newlist = list(set(links))\n",
    "    with open(filepath, 'w') as file:\n",
    "        file.writelines([str(line) + \"\\n\" for line in newlist])\n",
    "    print(\"New:\",len(newlist))\n",
    "    \n",
    "def downloadLinks(links,folderpath):\n",
    "    ln = len(links)\n",
    "    failedDownloads = []\n",
    "    for i,url in enumerate(links):\n",
    "        clear_output(wait=True)\n",
    "        filename = getlinkparams(url)['dl']\n",
    "        path = folderpath+'/'+filename\n",
    "        if not os.path.exists(path):\n",
    "            response = requests.get(url)\n",
    "            if response.status_code == 200:\n",
    "                print('[ '+str(int( ((i+1)/ln)*100 ) )+'% ] '+ filename + ' Downloaded')\n",
    "                # Save the file to a specific folder\n",
    "                with open(path, 'wb') as file:\n",
    "                    file.write(response.content)\n",
    "            else:\n",
    "                print(filename + 'Download failed')\n",
    "                failedDownloads.append(link)\n",
    "        else:\n",
    "            print('[ '+str(int( ((i+1)/ln)*100 ) )+'% ] skipping '+ filename)\n",
    "            \n",
    "def buildDataset(dataset_name,train_links,validation_links,classes):\n",
    "    train_path = dataset_name+\"/train\"\n",
    "    validation_path = dataset_name+\"/validation\"\n",
    "    os.makedirs(train_path+\"/images\", exist_ok=True)\n",
    "    os.makedirs(validation_path+\"/images\", exist_ok=True)\n",
    "    os.makedirs(train_path+\"/labels\", exist_ok=True)\n",
    "    os.makedirs(validation_path+\"/labels\", exist_ok=True)\n",
    "    with open(dataset_name+\"/classes.txt\", 'w') as f:\n",
    "        f.writelines([f\"{line}\\n\" for line in classes])\n",
    "    downloadLinks(train_links,train_path+\"/images\")\n",
    "    downloadLinks(validation_links,validation_path+\"/images\")\n",
    "\n",
    "def fixDataset(datasetname):\n",
    "    labelpaths = glob.glob(datasetname+'/**/*.txt', recursive=True)\n",
    "    imagepaths = glob.glob(datasetname+'/**/*.jpg', recursive=True)\n",
    "    labelfilenames = []\n",
    "    pairs = []\n",
    "    wrong_directory = []\n",
    "    withoutlabel = []\n",
    "    duplicates = []\n",
    "    imagefilenames = []\n",
    "    \n",
    "    for labelpath in labelpaths:\n",
    "        labelfilenames.append(labelpath.split('/')[-1][:-3])\n",
    "        \n",
    "    for imagepath in imagepaths:\n",
    "        imagesplit = imagepath.split('/')\n",
    "        if imagesplit[-1] in imagefilenames:\n",
    "            duplicates.append(imagepath)\n",
    "            print(\"found duplicate: \",imagepath)\n",
    "        imagefilenames.append(imagesplit[-1])\n",
    "\n",
    "    if len(duplicates) > 0:\n",
    "        print(\"found \",len(duplicates),\" duplicates\")\n",
    "        print(\"fixing\")\n",
    "        \n",
    "        for duplicate in duplicates:\n",
    "            os.remove(duplicate)\n",
    "        \n",
    "    for imagepath in imagepaths:\n",
    "        imagesplit = imagepath.split('/')\n",
    "        labelfound = False\n",
    "        if imagesplit[-1][:-3] in labelfilenames:\n",
    "            for labelpath in labelpaths:\n",
    "                labelsplit = labelpath.split('/')\n",
    "                if labelsplit[-1][:-3] == imagesplit[-1][:-3]:\n",
    "                    labelfound = True\n",
    "                    #print((imagepath,labelpath))\n",
    "                    pairs.append((imagepath,labelpath))\n",
    "                    break\n",
    "        if not labelfound:\n",
    "            withoutlabel.append(imagepath)\n",
    "    print(len(pairs), \" pairs found for \",len(imagepaths),\" images\")\n",
    "    print(len(withoutlabel), \" images without label\")\n",
    "    for imagepath in withoutlabel:\n",
    "        print(imagepath)\n",
    "    for pair in pairs:\n",
    "        if pair[0].split(\"/\")[1] != pair[1].split(\"/\")[1]:\n",
    "            wrong_directory.append(pair)\n",
    "            #print(pair[0].split(\"/\")[1],pair[1].split(\"/\")[1])\n",
    "    if len(wrong_directory) > 0:\n",
    "        print(len(wrong_directory), \"labels in the wrong directory\")\n",
    "        print(\"fixing\")\n",
    "        for mismachedpair in wrong_directory:\n",
    "            splt = mismachedpair[1].split('/')\n",
    "            correctfolder = mismachedpair[0].split('/')[1] \n",
    "            #print(\"0:\"+mismachedpair[0])\n",
    "            #print(\"1:\"+mismachedpair[1])\n",
    "            #print(\"2:\"+splt[0]+\"/\"+correctfolder+\"/\"+\"/\".join(splt[2:]) )\n",
    "            os.rename(mismachedpair[1], splt[0]+\"/\"+correctfolder+\"/\"+\"/\".join(splt[2:]) )\n",
    "    #return pairs\n",
    "            \n",
    "def shuffleFile(filepath):\n",
    "    links = getLinks(filepath)\n",
    "    random.shuffle(links)\n",
    "    with open(filepath, 'w') as file:\n",
    "        file.writelines([str(line) + \"\\n\" for line in links])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "674e00b4-1b4c-405d-82fe-d6ce69f2e1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffleFile(\"licenseplates_dataset_links.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "e554bb6e-ba56-4988-97b9-bbceed60a3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffleFile(\"faces_dataset_links.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bc4a52ec-0ce0-45f7-8eba-2435c666b223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: 205\n",
      "New: 202\n"
     ]
    }
   ],
   "source": [
    "removeDuplicates(\"licenseplates_dataset_links.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f2a56d3-74ec-4251-877f-7e6ae0a89303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: 152\n",
      "New: 152\n"
     ]
    }
   ],
   "source": [
    "removeDuplicates(\"faces_dataset_links.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e281e184-89ab-4c57-8ae0-2e1c2aa8c6ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 100% ] pexels-roneferreira-2735037.jpgDownloaded\n"
     ]
    }
   ],
   "source": [
    "Faces_Dataset_links = getLinks(\"faces_dataset_links.txt\",\"faces_dataset\")\n",
    "Faces_Train,Faces_Validation = splitLinks(Faces_Dataset_links,0.8,shuffle=True)\n",
    "buildDataset(\"faces_dataset\",Faces_Train,Faces_Validation,['face'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cfbacbf1-1473-4eda-bad5-1a63917f74fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 100% ] downloading pexels-jibarofoto-2038781.jpg\n"
     ]
    }
   ],
   "source": [
    "Licenseplates_links = getLinks(\"licenseplates_dataset_links.txt\",\"licenseplates_dataset\")\n",
    "licenseplates_Train,licenseplates_Validation = splitLinks(Licenseplates_links,0.8,shuffle=True)\n",
    "buildDataset(\"licenseplates_dataset\",licenseplates_Train,licenseplates_Validation,['license plate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "46d4471f-00f9-40dd-bef1-cea91a363c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201  pairs found for  201  images\n",
      "0  images without label\n"
     ]
    }
   ],
   "source": [
    "fixDataset(\"licenseplates_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3966084e-3d83-454d-9efe-91a1a657066a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "207  pairs found for  207  images\n",
      "0  images without label\n"
     ]
    }
   ],
   "source": [
    "fixDataset(\"faces_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbb5334-54c2-4b6b-a52e-3551ea55bb3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
